&emsp;&emsp;算法与数据结构是程序的精髓与灵魂。所谓数据结构，就是数据在内存中的存储方式。所谓算法，是在数据结构的基础之上，针对某一特定问题产生了解决思路和方法。因此算法与数据结构中，数据结构是基础，算法是在基础之上的解决方案。

### 1.1 数据集合及其结构
#### 1.1.1 数据集合与列表
&emsp;&emsp; 在计算机的数据输入，输出和处理过程中，数据常常以集合的方式进行。许多基础的数据类型都和对象的**集合**有关，数据类型的值就是一组对象的集合，并通过添加，删除，访问等方式对**集合**进行操作。
&emsp;&emsp;&emsp;集合是由一个或多个确定的元素所构成的整体。集合里的元素类型不一定相同，同时集合里的元素没有顺序。数据集合按不同方式可以分为：**逻辑结构**和**存储结构**两类。逻辑结构**表示数据与数据之间的联系**被称为数据的逻辑。存储结构**表示数据在计算机存储空间的存放形式**。
&emsp;&emsp;&emsp;  (1). 逻辑结构包括**线性结构**，**集合结构**，**树形结构**和**图(网状)结构**。

![[../picture/Pasted image 20240526102821.png#pic_center|500]]

&emsp;&emsp; (2). 存储结构包括**顺序结构**，**链式结构**，**索引存储**和**散列存储**

![[../picture/Pasted image 20240526102857.png#pic_center|700]]

&emsp;&emsp;列表 (称线性列表) 的定义为：是一种数据项构成的有限序列，即按照一定的线性顺序，排列而成的数据项的集合。列表的概念是在集合的特征上形成的，它具有顺序，且长度是可变的。**列表最常见的表现形式有数组和链表**，而栈和队列则是两种特殊类型的列表。除此之外，向列表中添加、删除元素的具体实现方式会根据编程语言的不同而有所区分。

#### 1.1.2 计算机的数据运算
&emsp;&emsp; 程序中的所有数据在计算机内存中都是以二进制的形式储存的，即0、1两种状态。因此，计算机中的数据运算是以**位运算**的形式进行，位运算直接对整数在内存中的二进制位进行操作。计算机中常见的位运算有以下几种：
![[../picture/Pasted image 20231125154411.png#pic_center|650]]

### 1.2 数据存储结构
&emsp;&emsp; 数据结构是解决问题的过程中使用的容器， 容器是存放数据的地方，容器还提供了一定的处理数据的能力。同时数据结构也是一种缓存，使用数据结构是一种空间换时间思想的体现，恰当使用数据结构可以帮助我们高效地处理数据。所谓恰当，是指针对具体的问题场景，使用了合适的数据结构。常见的数据结构如下所示：

#### 1.2.1 数组与字符串
&emsp;&emsp; 数组是列表的实现方式之一，数组会用索引的数字来标识每项数据在数组中的位置，且在大多数编程语言中，索引是从 0 算起的。我们可以根据数组中的索引，快速访问数组中的元素。**数组中的元素在内存中是连续存储的，且每个元素占用相同大小的内存**。以数组 `["C", "O", "D", "E", "R"]` 为例，它的各元素对应的索引及内存地址如下图所示：
![[../picture/Pasted image 20240526104158.png#pic_center|500]]

#### 1.2.1 栈/队列


#### 1.2.2 哈希(散列)表
&emsp;&emsp;哈希表又称散列表，是根据关键码值( Key-Value) 而直接进行访问的数据结构。它结合了数组、链表以及二叉树之间的优点。哈希表的特点如下：
&emsp;&emsp;&emsp;(1) **访问速度快**：由于哈希函数可以将指定的 Key 都映射到一个地址上，所以在访问一个 Key 对应的 Value 时，可以直接跳到访问地址，因此对散列表进行添加、删除、修改、查找等任何操作时，速度都很快。
&emsp;&emsp;&emsp;(2) **需要额外空间**：由于哈希表是以空间换时间，所以为了能够有更好的性能，往往会考虑牺牲些空间。
&emsp;&emsp;&emsp;(3) **会发生哈希碰撞**：没有完美的散列函数，无论如何总会产生冲突。因此需要采用冲突解决方案。

&emsp;&emsp;哈希表将记录的存储位置与它的关键字之间建立一个确定的关系 H( Key )，使每个关键字和唯一的存储位置对应，这种关系H就是该哈希表的一个**哈希函数**。在查找时，只需要根据对应关系计算出给定的关键字值 _H( Key )_，就可以得到记录的存储位置。
![[../picture/Pasted image 20231125160754.png#pic_center|280]]
##### 1. 哈希函数与哈希冲突
###### (1). 哈希函数
&emsp;&emsp;从上面可以得知，哈希表的关键就是确定哈希函数，哈希函数是一种将“**键**”转换为“**索引**”的逻辑规则，哈希函数要能尽量把 _Key_ 均匀散布在表空间中（从而尽量减少冲突），同时又要有尽量快的计算速度，它的设计好坏对哈希表的性能影响巨大。因此哈希函数的设计通常需要考虑几个因素：
&emsp; &emsp;&emsp; (1). 计算哈希地址锁需要的时间：即哈希函数本身不能太复杂，如果哈希函数的计算耗时超过遍历数据的时效时，哈希函数也就没有意义可言。
&emsp; &emsp;&emsp; (2).关键字分布是否均匀，是否有规律可循。
&emsp; &emsp;&emsp; (3). 哈希函数要尽可能减少哈希冲突的发生。
 
&emsp;&emsp;常见的哈希函数如下：
&emsp;&emsp;&emsp;  ◎ **直接寻址法**：取关键字或关键字的某个线性函数值为散列地址，`Hash(key)= A * Key + B`。该方法使用时需要事先知道关键字的分布情况。
&emsp;&emsp;&emsp;  ◎ **除留余数法**：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。通常选择质数作为数 m 的值。`Hash(key) = key % capacity` ( 哈希桶大小 )  
&emsp;&emsp;&emsp;  ◎ **数字分析法**：通过对数据进行分析，选取数据中冲突较少的部分，并构造散列地址。
&emsp;&emsp;&emsp;  ◎ **平方取中法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。
&emsp;&emsp;&emsp;  ◎ **随机散列法**：使用随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。`H( key ) = random( key )`。
###### (2). 哈希冲突
&emsp; &emsp;虽然选择了合适的哈希函数，由于哈希函数有时对不同的 _Key_ 计算之后获得了相同的地址，从而不可避免的导致哈希冲突。当出现哈希冲突时可能会对原存储位置的数据造成覆盖、丢失。因此必须要对哈希冲突进行处理。常见的处理方式有两种：**闭散列 ( 开放地址法 - _Open Addressing_ )** 和 **开散列 ( 链地址法 - _Linear Probing_ )**。

**▧ 闭散列 - 开放地址法** 
&emsp; &emsp;&emsp;闭散列也叫做开放定址法，当发生哈希冲突时，若哈希表未被填满，说明哈希表中还有空的存储空间，这时会形成一个探查序列，沿此序列逐个地址探查，直到找到一个空位置 ( 开放的地址 )，将发生冲突的记录放到该地址中。以下有两种常用的方法用来寻找空的位置：
&emsp; &emsp; &emsp; ◎ **线性探测**：线性探测即从发生冲突的位置开始，依次向后探测，直到寻找到下一个空位置即可。它的基本公式是：`Hash (key) = (key + d) mod TableSize (d = 1,2,3,4....)`。
![[../picture/Pasted image 20231125162110.png#pic_center|450]]
&emsp; &emsp;&emsp;随着插入数据的增多， 插入的数据产生冲突的概率也增加了。哈希表中的元素越多，查找数据时的效率就越低。因此，<font color=red>**当哈希表中的元素增多时，若产生的冲突较多，所有冲突连成一片，则产生数据堆积，在插入数据时需要多次探测寻找位置，导致哈希表搜索效率降低，此时需要对哈希表进行扩容。**</font>为了更准确的表示何时需要进行扩容，提出了**载荷因子**。**载荷因子 = 表中元素的个数 / 散列表的空间大小**，载荷因子越大，产生哈希冲突的概率越高，载荷因子越小，哈希表中的空间利用率越低，产生哈希冲突的概率也越低。对于开放定址法，载荷因子一般控制在 0.8 以下。

&emsp;&emsp;&emsp;◎ **二次探测**：为了防止线性探测中出现的冲突数据堆积，二次探测将公式改为了：`Hash(key) = (key + d^2) mod TableSize (d = 1,2,3,4...)` 。
![[../picture/Pasted image 20231125162322.png#pic_center|500]]

**▧ 开散列 - 链地址法**    
&emsp; &emsp;&emsp;开散列又叫链地址法，首先对关键码 _Key_ 集合用哈希函数计算哈希地址，具有相同地址的 _Key_ 归于同一子集合，每一个子集称为一个桶，各个桶中的元素通过一个单链表链接起来，桶中存储各链表的头节点。
![[../picture/Pasted image 20231125162457.png]]
&emsp; &emsp;&emsp;由于开放地址法需要确保搜索效率而浪费了大量的空间，而表项所占的空间又比指针大得多，因此使用链地址法相较于开放地址法更加节省空间。**开散列的哈希桶，负载因子可以超过1，一般情况下控制在 [0.0，1.0] 之间**。由于桶的数量是一定的，随着元素的不断插入，每个桶中元素的个数不断增多，极端情况下，可能会导致一个桶中链表很长，影响哈希表的性能。因此，在一定条件下需要对哈希表进行增容 ( 将单链表结构改为红黑树结构 )，此时哈希表中的数据会全部重新插入到增容后的哈希表中，降低了冲突的概率。
#### 1.2.3 链表
&emsp; &emsp;链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。

#### 1.2.4 树
&emsp; &emsp;树是由结点或顶点和边组成的且**不存在着任何环**的一种数据结构。没有结点的树称为空 ( _null_ ) 树。一棵非空的树包括一个根结点，还有多个子结点，所有结点构成一个多级分层结构。树的基本结构如下图所示：
![[../picture/Pasted image 20231125162742.png#pic_center|700]]&emsp; &emsp;随着树的演进过程，树的种类不断增加，目前常见树的种类如下：
![[../picture/Pasted image 20231125162814.png#pic_center|550]]
##### 1. 二叉树
&emsp; &emsp;二叉树是树的一种常见的结构，其特点是每个结点至多只有两棵子树( 即二叉树中不存在度大于2的结点)，并且二叉树的子树有左右之分，其次序不能任意颠倒，若将其左、右子树颠倒，则成为另一棵不同的二叉树。即使树中结点只有一棵子树，也要区分它是左子树还是右子树。
![[../picture/Pasted image 20231125163152.png#pic_center|450]]
&emsp;&emsp;&emsp;在二叉树中，有几个特殊结构的二叉树：
&emsp;&emsp;&emsp;  **◎ 满二叉树**：一棵高度为h，且含有 $2^h-1$ 结点的二叉树称为满二叉树，即树中的每层都含有最多的结点。每个结点对应一个编号,对于编号为 _i_ 的结点，若有双亲，则其双亲为 $i/2$，若有左孩子，则左孩子为 _2i_。若有右孩子，则右孩子为 $2i + 1$。    
&emsp;&emsp;&emsp;  **◎ 完全二叉树**：高度为 _h_、有 _n_ 个结点的二叉树，当且仅当其每个结点都与高度为 _h_ 的满二叉树中编号为 *1 ~ n* 的结点一一对应时，称为完全二叉树。
![[../picture/Pasted image 20231125163428.png#pic_center|380]]
**▧ 二叉树性质**  
&emsp;&emsp;&emsp;对于二叉树，有以下几个性质：
&emsp;&emsp;&emsp;  ◎ 对任意一棵二叉树，若结点数量为 _n_，则边的数量为 $n-1$。
&emsp;&emsp;&emsp;  ◎ 非空二叉树上的叶子结点数量 = 度为2的结点数 + 1，即 $n_0 = n_2 + 1$ 
&emsp;&emsp;&emsp;  ◎ 非空二叉树上第 k 层上最多有 $2^{k-1}$ 个结点 $( k ≥ 1 )$     
&emsp;&emsp;&emsp;  ◎ 高度为 h 的二叉树最多有 $(2^h)-1$ 个结点     
&emsp;&emsp;&emsp;  ◎ 对于完全二叉树，按从上到下、从左到右的顺序依次编号 1 , 2，...， n，则有以下关系：
&emsp;&emsp;&emsp;&emsp; ① i >1时，结点 _i_ 的双亲的编号为 $i/2$，即当 _i_ 为偶数时， 它是左孩子。当 _i_ 为奇数时，它是右孩子。
&emsp;&emsp;&emsp;&emsp; ② 当 $2i ≤ n$ 时，结点 i 的左孩子编号为 2i，否则无左孩子。
&emsp;&emsp;&emsp;&emsp; ③ 当 $2i + 1 ≤ n$ 时，结点 i 的右孩子编号为 2i + 1，否则无右孩子。
&emsp;&emsp;&emsp;&emsp; ④ 结点 i 所在层次(深度)为 ${log_2i}+1$ 
&emsp;&emsp;&emsp;  ◎  具有 n 个 ( n > 0 ) 的结点完全二叉树的高度为 ${log_2n}+1$

**▧ 二叉树的存储结构**
&emsp;&emsp;&emsp;二叉树有两种存储结构：**顺序存储结构**和**链式存储结构**。
&emsp;&emsp;&emsp; **◎ 顺序存储结构**：二叉树的顺序存储是指用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树上的结点元素。依据二叉树的性质，**完全二叉树和满二叉树采用顺序存储比较合适**，树中结点的序号可以唯一地反映结点之间的逻辑关系，既可以最大程度的节省存储空间，又能利用数组元素的下标值确定结点在二叉树中的位置，以及结点之间的关系。     
&emsp;&emsp;&emsp; **◎链式存储结构**：二叉树每个结点最多有两个孩子，包含一个数据域和两个指针域。
![[../picture/Pasted image 20231125164429.png#pic_center|500]]
###### (1). 二叉树的遍历
&emsp;&emsp;二叉树遍历按深度与广度可以分为**深度优先遍历 _DFS_** 和**广度优先遍历 _BFS_**。按遍历顺序可以分为**前序遍历( 根 -> 左 -> 右 )，中序遍历( 左 -> 根 -> 右 ) 和后序遍历( 左 -> 右 -> 根 )**。根据二叉树的遍历顺序关系可以逆向推解出二叉树的结构。前序遍历，中序遍历和后序变遍历之间的关系如下图所示：
![[../picture/Pasted image 20231125164659.png#pic_center]]
&emsp;&emsp;&emsp;从图中看出，通过中序遍历可以得知左子树的长度为 $inroot - inleft - 1$，因此**已知前序遍历和中序遍历、中序遍历和后序遍历可以确定唯一的一个二叉树，但如果只知道前序遍历和后序遍历则无法确定左右子树的长度，从而无法确认二叉树**。
#### 1.2.5 
---
### 1.3 算法
&emsp;&emsp;算法与数据结构之间的关系是相互依存的，算法需要数据结构来存储和操作数据，而数据结构需要算法来操作和处理数据。在算法问题中，重要的是对问题的理解和思考，从而选取合适的算法。面对一个问题，存在不同的结题思路，如何选取一个合适的算法就需要对各个算法的本质进行深入的了解。
#### 1.3.1 算法时间复杂度计算
&emsp;&emsp;算法的时间复杂度是一个函数，它定性描述该算法的运行时间，时间复杂度常用大O符号表述，**不包括这个函数的低阶项和首项系数**。<font color=red>**程序的运行时间与算法的时间复杂度相关，也和数据规模有关。**</font>一个合适的程序需要根据不同的数据规模选取不同时间复杂度的算法。如果可以在1s内解决问题，那么对应的处理数据的数量级如下所示：
![[../picture/Pasted image 20231125165206.png#pic_center|200]]
**▧ 常见程序的算法复杂度分析** 
&emsp;&emsp;&emsp;在计算程序性能时，虽然经常化简为最高项 $2N^2+cN ≈ 2N^2$ ，但当常数项很大时，如 $c=10^6$，我们也不能忽略常数项。
![[../picture/Pasted image 20231125165326.png#pic_center|700]]
**▧ 提高程序的性能**  
&emsp;&emsp;&emsp;要提高程序的性能，就是降低或稳定程序的时间复杂度，一般从两个方面进行： 
&emsp;&emsp;&emsp;  ◎ **处理对于输入的依赖**：程序计算的目的就是找到输入集合的性质，因此如果我们能够在集合中找到其性质，就可以使用经典的数学分析来简化程序处理对输入的依赖。     
&emsp;&emsp;&emsp;  ◎ **最坏情况下性能的保证**：保证程序的性能下限。     
&emsp;&emsp;&emsp;  ◎ **随机化算法**：尽快能的保证算法的随机性。如对随机算法的改进。

#### 1.3.2 算法思想
&emsp;&emsp; 面对一个问题，存在不同的结题思路，因此学习算法就要面对问题取求解。

##### 1.递归思想
&emsp;&emsp; 在数学与计算机科学中，递归( _Recursion_ )是指在函数的定义中使用函数自身的方法。实际上，递归其包含了两个意思：**递** 和 **归**，这正是递归思想的精华所在。**递归就是有去 ( 递去 ) 有回 ( 归来 )**，其本质是<font color=red>**将递归的函数在递去的过程中入栈 (操作系统层面的函数调用栈)，在归来的过程中出栈，并在入栈过程中缓存了当前递归状态的函数中的局部变量的内容**</font>。    
&emsp;&emsp;&emsp;  ◎ **“递去”**是指：递归问题必须可以分解 ( 展开 ) 为若干个规模较小，与原问题形式相同的子问题，这些子问题可以用相同的解题思路来解决。    
&emsp;&emsp;&emsp;  ◎ **“归来”**是指：递归问题的演化过程是一个从大到小，由近及远的过程，并且会有一个明确的终点 (临界点)，一旦到达了这个临界点，就不用再继续走下去。最后从这个临界点开始，原路返回到原点，原问题解决。
![[../picture/Pasted image 20231125165623.png#pic_center|600]]
&emsp;&emsp;&emsp;递归的基本思想就是**把规模大的问题转化为规模小的相似的子问题来解决**。特别地，在函数实现时，因为解决大问题的方法和解决小问题的方法往往是同一个方法，所以就产生了函数调用它自身的情况，这也正是递归的定义所在。格外需要注意的是，**这个解决问题的函数必须有明确的结束条件，否则就会导致无限递归的情况**。因此递归存在以下**三要素**：   
&emsp;&emsp;&emsp;  ◎ **明确递归终止条件**：程序一旦到达了这个临界点，说明当前问题已经被分解为最小子问题，此时就不用继续往下递去而是开归来。    
&emsp;&emsp;&emsp;  ◎ **给出递归终止时的处理办法**：在递归的临界点，应该给出这个最小子问题的解决方案。一般地，最小子问题的解决方案是直观的、容易的。    
&emsp;&emsp;&emsp;  ◎ **提取重复的逻辑，缩小问题规模**：递归问题必须可以分解为若干个规模较小、与原问题形式相同的子问题。因此需要抽象出一个干净利落的重复的逻辑，以便使用相同的方式解决子问题。
###### (1). 递归算法的编程模型
&emsp;&emsp;在明确递归算法设计三要素后，在编写算法时，通常有两种典型的递归算法设计模型：
```
① 模型一：在递去的过程中解决问题  
function recursion(大规模){  
    if (end_condition){    // 明确的递归终止条件  
        end;      // 简单情景  
    }else{               // 在将问题转换为子问题的每一步，解决该步中剩余部分的问题  
        solve;             // 递去过程中不断解决问题  
        recursion(缩小规模); // 递到最深处后，不断地归来  
    }  
}  
② 模型二：在归来的过程中解决问题  
function recursion(大规模){  
    if (end_condition){   // 明确的递归终止条件  
        end;     // 简单情景  
    }else{                // 先将问题全部描述展开，再由尽头“返回”依次解决每步中剩余部分的问题  
        recursion(缩小规模);// 递去  
        solve;             // 归来过程中不断解决问题  
    }  
}
```
###### (2). 递归算法的应用场景
&emsp;&emsp;递归算法一般用于解决三类问题：    
&emsp;&emsp;&emsp;  ◎ **问题的定义是按递归定义的 ( 如 _Fibonacci_ 函数，阶乘，… )**   
&emsp;&emsp;&emsp;  ◎ **问题的解法是递归的 ( 有些问题只能使用递归方法来解决，例如，汉诺塔问题，… )**    
&emsp;&emsp;&emsp;  ◎ **数据结构是递归的 ( 如链表、树等的操作，包括树的遍历，树的深度，… )**

##### 2. 查找算法
&emsp;&emsp; 查找是在大量的信息中寻找一个特定的信息元素。在非数值运算问题中，数据存储量一般很大，为了在大量信息中找到某些值，需要用到查找技术，为了提高查找效率，需要对一些数据进行排序。查找和排序的数据处理量占有非常大的比重，故查找和排序的有效性直接影响到算法的性能，因而查找和排序是重要的处理技术。查找两种常见的分类：
