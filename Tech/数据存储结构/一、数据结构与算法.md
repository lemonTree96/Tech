&emsp;&emsp;算法与数据结构是程序的精髓与灵魂。所谓数据结构，就是数据在内存中的存储方式。所谓算法，是在数据结构的基础之上，针对某一特定问题产生了解决思路和方法。因此算法与数据结构中，数据结构是基础，算法是在基础之上的解决方案。
><font color=SlateBlue>  <u>**Q1. 什么是算法 (algorithm)  ？**</u></font>
>&emsp;&emsp;&emsp;算法是在有限时间内解决特定问题的一组指令或操作步骤，它具有以下特性。
>&emsp; &emsp; &emsp; ① 问题是明确的，包含清晰的输入和输出定义。
>&emsp; &emsp; &emsp; ② 具有可行性，能够在有限步骤、时间和内存空间下完成。
>&emsp; &emsp; &emsp; ③ 各步骤都有确定的含义，在相同的输入和运行条件下，输出始终相同。
>
><font color=SlateBlue>  <u>**Q2. 什么是数据结构 (data structure)  ？**</u></font>
>&emsp;&emsp;&emsp;数据结构是组织和存储数据的方式，涵盖数据内容、数据之间关系和数据操作方法，它具有以下目标。
>&emsp; &emsp; &emsp; ① 空间占用尽量少，以节省计算机内存。
>&emsp; &emsp; &emsp; ② 数据操作尽可能快速，涵盖数据访问、添加、删除、更新等。
>&emsp; &emsp; &emsp; ③ 提供简洁的数据表示和逻辑信息，以便算法高效运行。
>
><font color=SlateBlue>  <u>**Q3. 数据结构与算法的关系 ？**</u></font>
>&emsp; &emsp; &emsp; ① 数据结构是算法的基石。数据结构为算法提供了结构化存储的数据，以及操作数据的方法。
>&emsp; &emsp; &emsp; ② 算法是数据结构发挥作用的舞台。数据结构本身仅存储数据信息，结合算法才能解决特定问题。
>&emsp; &emsp; &emsp; ③ 算法通常可以基于不同的数据结构实现，但执行效率可能相差很大，选择合适的数据结构是关键。
>
>![[../picture/Pasted image 20240809214403.png#pic_center|450]]


### 1.1 数据集合及其结构
#### 1.1.1 数据集合与列表
&emsp;&emsp; 在计算机的数据输入，输出和处理过程中，数据常常以集合的方式进行。许多基础的数据类型都和对象的**集合**有关，数据类型的值就是一组对象的集合，并通过添加，删除，访问等方式对**集合**进行操作。
&emsp;&emsp;&emsp;集合是由一个或多个确定的元素所构成的整体。集合里的元素类型不一定相同，同时集合里的元素没有顺序。数据集合按不同方式可以分为：**逻辑结构**和**存储结构**两类。逻辑结构**表示数据与数据之间的联系**被称为数据的逻辑。存储结构**表示数据在计算机存储空间的存放形式**。
&emsp;&emsp;&emsp; ◎ 逻辑结构包括**线性数据结构** 和 **非线性数据结构**。
&emsp;&emsp;&emsp;&emsp;   ① **线性数据结构**：数组、链表、栈、队列、哈希表，元素之间是一对一的顺序关系
&emsp;&emsp;&emsp;&emsp;   ② **非线性数据结构**：树、堆、图、哈希表。

![[../picture/Pasted image 20240811163552.png]]

&emsp;&emsp;◎ 存储结构包括**连续空间存储**和**分散空间存储**。**所有数据结构都是基于数组、链表或二者的组合实现的**。
&emsp;&emsp;&emsp;&emsp; ● **基于数组可实现**：栈、队列、哈希表、树、堆、图、矩阵、张量（维度 ≥3 的数组）等。
&emsp;&emsp;&emsp;&emsp; ● **基于链表可实现**：栈、队列、哈希表、树、堆、图等

![[../picture/Pasted image 20240811164002.png#pic_center|690]]

#### 1.1.2 计算机的数据运算
&emsp;&emsp; 程序中的所有数据在计算机内存中都是以二进制的形式储存的，即0、1两种状态。因此，计算机中的数据运算是以**位运算**的形式进行，位运算直接对整数在内存中的二进制位进行操作。计算机中常见的位运算有以下几种：

![[../picture/Pasted image 20231125154411.png#pic_center|650]]
&emsp;
&emsp;

### 1.2 数据存储结构
&emsp;&emsp; 数据结构是解决问题的过程中使用的容器， 容器是存放数据的地方，容器还提供了一定的处理数据的能力。同时数据结构也是一种缓存，使用数据结构是一种空间换时间思想的体现，恰当使用数据结构可以帮助我们高效地处理数据。所谓恰当，是指针对具体的问题场景，使用了合适的数据结构。

#### 1.2.1 数组 array
&emsp;&emsp; 数组是列表的实现方式之一，其将相同类型的元素存储在连续的内存空间中。数组会用索引的数字来标识每项数据在数组中的位置，且在大多数编程语言中，索引是从 0 算起的，**索引本质上是内存地址的偏移量**。我们可以根据数组中的索引，快速访问数组中的元素，在数组中访问元素非常高效，我们可以在 $O(1)$ 时间内随机访问数组中的任意一个元素。**数组中的元素在内存中是连续存储的，且每个元素占用相同大小的内存**。以数组 `["C", "O", "D", "E", "R"]` 为例，它的各元素对应的索引及内存地址如下图所示：
![[../picture/Pasted image 20240526104158.png#pic_center|500]]


**▧ 数组的优点与局限性** 
- **优点**：
	- ①  **空间效率高**：数组为数据分配了连续的内存块，无须额外的结构开销。
	- ② **支持随机访问**：数组允许在 O(1) 时间内访问任何元素。
	- ③ **缓存局部性**：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。
- **局限性**：
	- ①  **插入与删除效率低**：当数组中元素较多时，插入与删除操作需要移动大量的元素。
	- ②  **长度不可变**：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。
	- ③ **空间浪费**：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。

**▧ 数组的典型应用** 
&emsp;&emsp; 数组是一种基础且常见的数据结构，既频繁应用在各类算法之中，也可用于实现各种复杂数据结构。其主要有一下几个应用：
&emsp;&emsp;&emsp; ① **随机访问**：如果我们想随机抽取一些样本，那么可以用数组存储，并生成一个随机序列，根据索引实现随机抽样。
&emsp;&emsp;&emsp; ② **排序和搜索**：数组是排序和搜索算法最常用的数据结构。快速排序、归并排序、二分查找等都主要在数组上进行。
&emsp;&emsp;&emsp; ③ **查找表**：当需要快速查找一个元素或其对应关系时，可以使用数组作为查找表。假如我们想实现字符到 ASCII 码的映射，则可以将字符的 ASCII 码值作为索引，对应的元素存放在数组中的对应位置。
&emsp;&emsp;&emsp; ④ **机器学习**：神经网络中大量使用了向量、矩阵、张量之间的线性代数运算，这些数据都是以数组的形式构建的。数组是神经网络编程中最常使用的数据结构。
&emsp;&emsp;&emsp; ⑤  **数据结构实现**：数组可以用于实现栈、队列、哈希表、堆、图等数据结构。例如，图的邻接矩阵实际是一个二维数组。

#### 1.2.2 链表
&emsp; &emsp;内存空间是所有程序的公共资源，在一个复杂的系统运行环境下，空闲的内存空间可能散落在内存各处。存储数组的内存空间必须是连续的，而当数组非常大时，内存可能无法提供如此大的连续空间。此时链表的灵活性优势就体现出来了。数值与列表的主要优缺点如下：
![[../picture/Pasted image 20240818221745.png#pic_center|560]]
&emsp; &emsp; &emsp;链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表其中的每个元素都是一个节点对象，每个节点都包含两项数据：节点的“值”和指向下一节点的“引用”。各个节点通过“引用”相连接。引用记录了下一个节点的内存地址，通过它可以从当前节点访问到下一个节点。由于链表节点 `ListNode` 除了包含值，还需额外保存一个引用 (指针)，因此在相同数据量下，**链表比数组占用更多的内存空间**。
![[../picture/Pasted image 20240811180152.png#pic_center|700]]

**▧ 常见的列表类型** 
- ① **单向链表**：即前面介绍的普通链表。单向链表的节点包含值和指向下一节点的引用两项数据。我们将首个节点称为头节点，将最后一个节点称为尾节点，尾节点指向空 `None` 。**单向链表通常用于实现栈、队列、哈希表和图等数据结构**。
	-  **栈与队列**：当插入和删除操作都在链表的一端进行时，它表现的特性为先进后出，对应栈；当插入操作在链表的一端进行，删除操作在链表的另一端进行，它表现的特性为先进先出，对应队列。
	- **哈希表**：链式地址是解决哈希冲突的主流方案之一，在该方案中，所有冲突的元素都会被放到一个链表中。
	- **图**：邻接表是表示图的一种常用方式，其中图的每个顶点都与一个链表相关联，链表中的每个元素都代表与该顶点相连的其他顶点。
- ② **环形链表**：如果我们令单向链表的尾节点指向头节点 (首尾相接)，则得到一个环形链表。在环形链表中，任意节点都可以视作头节点。**环形链表常用于需要周期性操作的场景，比如操作系统的资源调度。**
	-  **时间片轮转调度算法**：在操作系统中，时间片轮转调度算法是一种常见的 CPU 调度算法，它需要对一组进程进行循环。每个进程被赋予一个时间片，当时间片用完时，CPU 将切换到下一个进程。这种循环操作可以通过环形链表来实现。
	- **数据缓冲区**：在某些数据缓冲区的实现中，也可能会使用环形链表。比如在音频、视频播放器中，数据流可能会被分成多个缓冲块并放入一个环形链表，以便实现无缝播放。
-  ③ **双向链表**：与单向链表相比，双向链表记录了两个方向的引用。双向链表的节点定义同时包含指向后继节点 (下一个节点) 和前驱节点 (上一个节点) 的引用。相较于单向链表，双向链表更具灵活性，可以朝两个方向遍历链表，但相应地也需要占用更多的内存空间。**双向链表常用于需要快速查找前一个和后一个元素的场景**。
	- **高级数据结构**：比如在红黑树、B 树中，我们需要访问节点的父节点，这可以通过在节点中保存一个指向父节点的引用来实现，类似于双向链表。
	- **浏览器历史**：在网页浏览器中，当用户点击前进或后退按钮时，浏览器需要知道用户访问过的前一个和后一个网页。双向链表的特性使得这种操作变得简单。
	- **LRU 算法**：在缓存淘汰（LRU）算法中，我们需要快速找到最近最少使用的数据，以及支持快速添加和删除节点。这时候使用双向链表就非常合适。

![[../picture/Pasted image 20240811190759.png#pic_center|380]]


#### 1.2.3 栈/队列
##### 1. 栈 stack
&emsp;&emsp; 栈是一种遵循<font color=red>**先入后出 (FILO - first in last out)**</font>逻辑的线性数据结构。通常把堆叠元素的顶部称为“栈顶”，底部称为“栈底”。将把元素添加到栈顶的操作叫作“入栈”，删除栈顶元素的操作叫作“出栈”。
![[../picture/Pasted image 20240821234338.png#pic_center|280]]

&emsp;&emsp; 栈遵循先入后出的原则，因此我们只能在栈顶添加或删除元素。然而，数组和链表都可以在任意位置添加和删除元素，**因此栈可以视为一种受限制的数组或链表**。栈有两种实现方式：**顺序栈**和**链表栈**。
&emsp;&emsp;&emsp; ① 顺序栈：顺序栈是通过数组来存储栈中的元素，并通过栈顶指针指示栈顶元素在数组中的位置。顺序栈除了遍历栈中的元素的操作时间复杂度为$O(n)$外，其余：入栈、出栈、取栈顶元素、判断栈是否为空操作的时间复杂度均为$O(1)$。
&emsp;&emsp;&emsp; ② 链表栈：链表栈是一种基于链表实现的栈，其无需事先分配固定长度的存储空间，栈的长度可以动态增长或缩小，避免了顺序栈可能存在的空间浪费和存储溢出问题。链栈的入栈、出栈的时间复杂度均为$O(1)$。

**▧ 栈的典型应用**
-  **浏览器中的后退与前进、软件中的撤销与反撤销**。每当我们打开新的网页，浏览器就会对上一个网页执行入栈，这样我们就可以通过后退操作回到上一个网页。后退操作实际上是在执行出栈。如果要同时支持后退和前进，那么需要两个栈来配合实现。
- **程序内存管理**。每次调用函数时，系统都会在栈顶添加一个栈帧，用于记录函数的上下文信息。在递归函数中，向下递推阶段会不断执行入栈操作，而向上回溯阶段则会不断执行出栈操作。

##### 2. 队列 queue
&emsp;&emsp;  队列是一种遵循<font color=red>**先入先出 (FIFO - first in first out) **</font>规则的线性数据结构。通常将队列头部称为“队首”，尾部称为“队尾”，将把元素加入队尾的操作称为“入队”，删除队首元素的操作称为“出队”。
![[../picture/Pasted image 20240823225458.png#pic_center|300]]

**▧ 队列的典型应用**
-  **淘宝订单**。购物者下单后，订单将加入队列中，系统随后会根据顺序处理队列中的订单。在双十一期间，短时间内会产生海量订单，高并发成为工程师们需要重点攻克的问题。
- **各类待办事项**。任何需要实现“先来后到”功能的场景，例如打印机的任务队列、餐厅的出餐队列等，队列在这些场景中可以有效地维护处理顺序。

#### 1.2.4 哈希(散列)表
&emsp;&emsp;哈希表又称散列表，是根据关键码值( Key-Value) 而直接进行访问的数据结构。它结合了数组、链表以及二叉树之间的优点。哈希表的特点如下：
&emsp;&emsp;&emsp;① **访问速度快**：由于哈希函数可以将指定的 Key 都映射到一个地址上，所以在访问一个 Key 对应的 Value 时，可以直接跳到访问地址，因此对散列表进行添加、删除、修改、查找等任何操作时，速度都很快。**在哈希表中进行增删查改的时间复杂度都是 $O(1)$**。
&emsp;&emsp;&emsp;② **需要额外空间**：由于哈希表是以空间换时间，所以为了能够有更好的性能，往往会考虑牺牲些空间。
&emsp;&emsp;&emsp;③ **会发生哈希碰撞**：没有完美的散列函数，无论如何总会产生冲突。因此需要采用冲突解决方案。

![[../picture/Pasted image 20240824092246.png#pic_center|320]]

&emsp;&emsp;哈希表将记录的存储位置与它的关键字之间建立一个确定的关系 H( Key )，使每个关键字和唯一的存储位置对应，这种关系H就是该哈希表的一个**哈希函数**。在查找时，只需要根据对应关系计算出给定的关键字值 H( Key )，就可以得到记录的存储位置。最简单的哈希表可以用一个数组来实现。在哈希表中，我们将数组中的每个空位称为桶 (bucket)，每个桶可存储一个键值对。因此，查询操作就是找到 `key` 对应的桶，并在桶中获取 `value` 。
&emsp;&emsp;&emsp;注意：**只有不可变对象才可作为哈希表的`key`**，**因为对象的哈希值通常是基于内存地址生成的**，当对象发生变化时 (如new一个新对象)，其内存地址会发生变化，对应的哈希值也会发生变化。

![[../picture/Pasted image 20231125160754.png#pic_center|280]]
##### 1. 哈希函数与哈希冲突
###### (1). 哈希函数
&emsp;&emsp;从上面可以得知，哈希表的关键就是确定哈希函数，哈希函数是一种将“**键**”转换为“**索引**”的逻辑规则，哈希函数要能尽量把 _Key_ 均匀散布在表空间中（从而尽量减少冲突），同时又要有尽量快的计算速度，它的设计好坏对哈希表的性能影响巨大。因此哈希函数的设计通常需要考虑几个因素：
&emsp; &emsp; &emsp; ① 计算哈希地址锁需要的时间：即哈希函数本身不能太复杂，如果哈希函数的计算耗时超过遍历数据的时效时，哈希函数也就没有意义可言。
&emsp; &emsp; &emsp; ② 关键字分布是否均匀，是否有规律可循。
&emsp; &emsp; &emsp; ③  哈希函数要尽可能减少哈希冲突的发生。
 
&emsp;&emsp;常见的哈希函数如下：
&emsp; &emsp; &emsp;  ◎ **直接寻址法**：取关键字或关键字的某个线性函数值为散列地址，`Hash(key)= A * Key + B`。该方法使用时需要事先知道关键字的分布情况。
&emsp;&emsp; &emsp;  ◎ **除留余数法**：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。通常选择质数作为数 m 的值。`Hash(key) = key % capacity` ( 哈希桶大小 )  
&emsp;&emsp; &emsp;  ◎ **数字分析法**：通过对数据进行分析，选取数据中冲突较少的部分，并构造散列地址。
&emsp;&emsp; &emsp;  ◎ **平方取中法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。
&emsp;&emsp; &emsp;  ◎ **随机散列法**：使用随机函数，取Key的随机值作为散列地址，用于Key长度不同的场合。`H( key ) = random( key )`。
###### (2). 哈希冲突
&emsp; &emsp;虽然选择了合适的哈希函数，由于哈希函数有时对不同的 Key 计算之后获得了相同的地址，从而不可避免的导致哈希冲突。当出现哈希冲突时可能会对原存储位置的数据造成覆盖、丢失。因此必须要对哈希冲突进行处理。常见的处理方式有两种：**闭散列 ( 开放地址法 - Open Addressing )** 和 **开散列 ( 链地址法 - Linear Probing )**。

**▧ 闭散列 - 开放地址法** 

&emsp; &emsp;闭散列也叫做开放定址法，当发生哈希冲突时，若哈希表未被填满，说明哈希表中还有空的存储空间，这时会形成一个探查序列，沿此序列逐个地址探查，直到找到一个空位置 ( 开放的地址 )，将发生冲突的记录放到该地址中。

&emsp;&emsp; 随着插入数据的增多， 插入的数据产生冲突的概率也增加了。哈希表中的元素越多，查找数据时的效率就越低。因此，<font color=red>**当哈希表中的元素增多时，若产生的冲突较多，所有冲突连成一片，则产生数据堆积，在插入数据时需要多次探测寻找位置，导致哈希表搜索效率降低，此时需要对哈希表进行扩容。**</font>为了更准确的表示何时需要进行扩容，提出了**载荷因子**。**载荷因子 = 表中元素的个数 / 散列表的空间大小**，载荷因子越大，产生哈希冲突的概率越高，载荷因子越小，哈希表中的空间利用率越低，产生哈希冲突的概率也越低。对于开放定址法，载荷因子一般控制在 0.8 以下。

&emsp;&emsp;需要注意的是，<font color=red>**不能在开放寻址哈希表中直接删除元素**</font>，因为删除元素会在数组内产生一个空桶 None ，而当查询元素时，线性探测到该空桶就会返回，因此在该空桶之下的元素都无法再被访问到。为了解决该问题，我们可以采用**懒删除** ( lazy deletion )机制：它不直接从哈希表中移除元素，而是**利用一个常量 TOMBSTONE 来标记这个桶**。在该机制下，TOMBSTONE 和 None 都代表空桶，都可以放置键值对。但不同的是，线性探测到 TOMBSTONE 时应该继续遍历，因为其之下可能还存在键值对。然而，**懒删除可能会加速哈希表的性能退化**。因为每次删除操作都会产生一个删除标记 TOMBSTONE，随着 TOMBSTONE 的增加，搜索时间也会增加，因为线性探测可能需要跳过多个 TOMBSTONE 才能找到目标元素。<font color=green>为了优化查询效率，在线性探测中记录遇到的首个  TOMBSTONE 的索引，并将搜索到的目标元素与该 TOMBSTONE 交换位置。这样元素会被移动至距离理想位置 (探测起始点) 更近的桶。</font>

&emsp;&emsp;以下有两种常用的方法用来寻找空的位置：
&emsp;&emsp;&emsp; ◎ **线性探测**：线性探测即从发生冲突的位置开始，依次向后探测，直到寻找到下一个空位置即可。它的基本公式是：`Hash (key) = (key + d) mod TableSize (d = 1,2,3,4....)`。
![[../picture/Pasted image 20231125162110.png#pic_center|450]]

&emsp;&emsp; ◎ **二次(平方)探测**：为了防止线性探测中出现的冲突数据堆积，二次探测将公式改为了：`Hash(key) = (key + d^2) mod TableSize (d = 1,2,3,4...)` 。
![[../picture/Pasted image 20231125162322.png#pic_center|500]]

**▧ 开散列 - 链地址法**    

&emsp;&emsp;开散列又叫链地址法，首先对关键码 Key 集合用哈希函数计算哈希地址，具有相同地址的 Key 归于同一子集合，每一个子集称为一个桶，各个桶中的元素通过一个单链表链接起来，桶中存储各链表的头节点。
![[../picture/Pasted image 20231125162457.png#pic_center|650]]
&emsp; &emsp;&emsp;由于开放地址法需要确保搜索效率而浪费了大量的空间，而表项所占的空间又比指针大得多，因此使用链地址法相较于开放地址法更加节省空间。**开散列的哈希桶，负载因子可以超过1，一般情况下控制在 [0.0，1.0] 之间**。由于桶的数量是一定的，随着元素的不断插入，每个桶中元素的个数不断增多，极端情况下，可能会导致一个桶中链表很长，影响哈希表的性能。因此，在一定条件下需要对哈希表进行增容 ( 将单链表结构改为红黑树结构 )，此时哈希表中的数据会全部重新插入到增容后的哈希表中，降低了冲突的概率。

###### (3). 哈希算法
&emsp;&emsp;上面提到的哈希冲突处理方法，无论是开放寻址还是链式地址，它们只能保证哈希表可以在发生冲突时正常工作，而无法减少哈希冲突的发生。如果哈希冲突过于频繁，哈希表的性能则会急剧劣化。
![[../picture/Pasted image 20240824151309.png#pic_center|450]]

&emsp;&emsp;Hash 键值对的分布情况由哈希函数决定 `index = hash(key) % capacity`，当哈希表容量 capacity 固定时，**哈希算法 `hash()` 决定了输出值**。哈希算法除了可以用于实现哈希表，还广泛应用于其他领域中：
&emsp;&emsp;&emsp; ● **密码存储**：为了保护用户密码的安全，系统通常不会直接存储用户的明文密码，而是存储密码的哈希值。当用户输入密码时，系统会对输入的密码计算哈希值，然后与存储的哈希值进行比较。如果两者匹配，那么密码就被视为正确。
&emsp;&emsp;&emsp; ● **数据完整性检查**：数据发送方可以计算数据的哈希值并将其一同发送；接收方可以重新计算接收到的数据的哈希值，并与接收到的哈希值进行比较。如果两者匹配，那么数据就被视为完整。

&emsp;&emsp;针对以上的应用场景，哈希算法应具备以下特点：
&emsp;&emsp; &emsp; ① **确定性**：对于相同的输入，哈希算法应始终产生相同的输出。
&emsp;&emsp; &emsp; ② **效率高**：计算哈希值的过程应该足够快。计算开销越小，哈希表的实用性越高。
&emsp;&emsp; &emsp; ③ **均匀分布**：哈希算法应使得键值对均匀分布在哈希表中。分布越均匀，哈希冲突的概率就越低。
&emsp;&emsp; &emsp; ④ **单向性**：无法通过哈希值反推出关于输入数据的任何信息 (针对密码学所需要的安全特性)。
&emsp;&emsp; &emsp; ⑤ **抗碰撞性**：应当极难找到两个不同的输入，使得它们的哈希值相同 (针对密码学所需要的安全特性)。
&emsp;&emsp; &emsp; ⑥ **雪崩效应**：输入的微小变化应当导致输出的显著且不可预测的变化 (针对密码学所需要的安全特性)。

**▧ 常用的哈希算法** 

&emsp;&emsp; 哈希算法的设计是一个需要考虑许多因素的复杂问题。在实际中，我们通常会用一些标准哈希算法，例如 MD5、SHA-1、SHA-2 和 SHA-3 等。它们可以将任意长度的输入数据映射到恒定长度的哈希值。
![[../picture/Pasted image 20240824214707.png#pic_center|480]]

**▧ 一致性哈希算法** 

&emsp;&emsp;一致性哈希算法，是一种特殊的哈希算法，目的是解决分布式缓存在移除或者添加一个服务器时，能够**尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系的问题**。所谓分布式缓存是将大批缓存数据分别存储到不同的缓存服务器当中。
![[../picture/Pasted image 20240824232952.png#pic_center|730]]
&emsp;&emsp; 一致性哈希算法本质上也是一种取模算法。一致性哈希对固定值 $2^{32}$ 取模，这就使得一致性算法具备良好的单调性：不管集群中有多少个节点，只要 key 值固定，那所请求的服务器节点也同样是固定的。其算法的工作原理如下：

![[../picture/Pasted image 20240825000616.png#pic_center|800]]

&emsp;&emsp;但是上面的模型如果**服务器节点太少或者出现热点数据 (数据倾斜)**，就会导致服务器节点上之间的<font color=orange>**数据分布不均匀**</font>。如果服务器节点太少，当某个服务器宕机时，它原本所负责的缓存数据将全部交由顺时针方向的下一个服务器节点处理。例如，当 B 退出时，它原本所负责的缓存将全部交给 C 处理。则 C 的访问压力会瞬间增大。如果 C 因为压力过大而崩溃，那么更大的压力又会向 D 压过去，最终导致出现<font color=orange>**缓存雪崩**</font>的问题。
&emsp;&emsp;&emsp;为了解决数据倾斜的问题，一致性哈希算法引入了虚拟节点机制，即对每一个物理服务节点映射多个虚拟节点，将这些虚拟节点计算哈希值并映射到哈希环上，并可以在hash环上<font color=orange>**均匀分布**</font>，当请求找到某个虚拟节点后，将被重新映射到具体的物理节点。虚拟节点越多，哈希环上的节点就越多，数据分布就越均匀。

![[../picture/Pasted image 20240825163524.png#pic_center|440]]

#### 1.2.5 树
&emsp; &emsp;树是由结点或顶点和边组成的且**不存在着任何环**的一种数据结构。没有结点的树称为空 (null) 树。一棵非空的树包括一个根结点，还有多个子结点，所有结点构成一个多级分层结构。树的基本结构如下图所示：
![[../picture/Pasted image 20231125162742.png#pic_center|800]]

&emsp; &emsp;随着树的演进过程，树的种类不断增加，目前常见树的种类如下：
![[../picture/Pasted image 20231125162814.png#pic_center|550]]
##### 1. 二叉树
&emsp; &emsp;二叉树是树的一种常见的结构，其特点是每个结点至多只有两棵子树( 即二叉树中不存在度大于2的结点)，并且二叉树的子树有左右之分，其次序不能任意颠倒，若将其左、右子树颠倒，则成为另一棵不同的二叉树。即使树中结点只有一棵子树，也要区分它是左子树还是右子树。
![[../picture/Pasted image 20231125163152.png#pic_center|450]]
&emsp;&emsp;&emsp;在二叉树中，有几个特殊结构的二叉树：
&emsp;&emsp;&emsp;  **① 满二叉树**：一棵高度为h，且含有 $2^h-1$ 结点的二叉树称为满二叉树，即树中的每层都含有最多的结点。每个结点对应一个编号,对于编号为 i 的结点，若有双亲，则其双亲为 $i/2$，若有左孩子，则左孩子为 2i。若有右孩子，则右孩子为 $2i + 1$。    
&emsp;&emsp;&emsp;  **② 完全二叉树**：高度为 h、有 n 个结点的二叉树，当且仅当其每个结点都与高度为 h 的满二叉树中编号为 1 ~ n  的结点一一对应时，称为完全二叉树。
&emsp;&emsp;&emsp;  **③ 完满二叉树**：完满二叉树除了叶节点之外，其余所有节点都有两个子节点。完满二叉树的所有节点的度都为0或2。
&emsp;&emsp;&emsp;  **④ 平衡二叉树**：平衡二叉树中任意节点的左子树和右子树的高度之差的绝对值不超过 1 。
![[../picture/Pasted image 20240825224617.png#pic_center|750]]

**▧ 二叉树性质**  

&emsp;&emsp;对于二叉树，有以下几个性质：
&emsp;&emsp; &emsp;  ◎ 对任意一棵二叉树，若结点数量为 n，则边的数量为 $n-1$。
&emsp;&emsp; &emsp;  ◎ 非空二叉树上的叶子结点数量 = 度为2的结点数 + 1，即 $n_0 = n_2 + 1$ 
&emsp;&emsp; &emsp;  ◎ 非空二叉树上第 k 层上最多有 $2^{k-1}$ 个结点 $( k ≥ 1 )$     
&emsp;&emsp; &emsp;  ◎ 高度为 h 的二叉树最多有 $(2^h)-1$ 个结点     
&emsp;&emsp; &emsp;  ◎ 对于完全二叉树，按从上到下、从左到右的顺序依次编号 1 , 2，...， n，则有以下关系：
&emsp;&emsp; &emsp; &emsp; ① i >1时，结点 i 的双亲的编号为 $i/2$，即当 _i_ 为偶数时， 它是左孩子。当 i 为奇数时，它是右孩子。
&emsp;&emsp; &emsp; &emsp; ② 当 $2i ≤ n$ 时，结点 i 的左孩子编号为 2i，否则无左孩子。
&emsp;&emsp; &emsp; &emsp; ③ 当 $2i + 1 ≤ n$ 时，结点 i 的右孩子编号为 2i + 1，否则无右孩子。
&emsp;&emsp; &emsp; &emsp; ④ 结点 i 所在层次(深度)为 ${log_2i}+1$ 
&emsp;&emsp; &emsp;  ◎  具有 n 个 ( n > 0 ) 的结点完全二叉树的高度为 ${log_2n}+1$

**▧ 二叉树的存储结构**

&emsp;&emsp;二叉树有两种存储结构：**顺序存储结构**和**链式存储结构**。
&emsp;&emsp;&emsp; **◎ 顺序存储结构**：二叉树的顺序存储是指用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树上的结点元素。依据二叉树的性质，**完全二叉树和满二叉树采用顺序存储比较合适**，树中结点的序号可以唯一地反映结点之间的逻辑关系，既可以最大程度的节省存储空间，又能利用数组元素的下标值确定结点在二叉树中的位置，以及结点之间的关系。     
&emsp;&emsp;&emsp; **◎链式存储结构**：二叉树每个结点最多有两个孩子，包含一个数据域和两个指针域。
![[../picture/Pasted image 20231125164429.png#pic_center|500]]
###### (1). 二叉树的遍历
&emsp;&emsp;二叉树遍历按深度与广度可以分为**深度优先遍历 DFS** 和**广度优先遍历 BFS (层序遍历)**。其中深度优先遍历又可以分为**前序遍历 (根->左->右)，中序遍历 (左->根->右) 和后序遍历 (左->右->根)**。根据二叉树的遍历顺序关系可以逆向推解出二叉树的结构。前序遍历，中序遍历和后序变遍历之间的关系如下图所示：

![[../picture/Pasted image 20231125164659.png#pic_center|780]]
&emsp;&emsp;&emsp;从图中看出，通过中序遍历可以得知左子树的长度为 $inroot - inleft - 1$，因此**已知前序遍历和中序遍历、中序遍历和后序遍历可以确定唯一的一个二叉树，但<font color=red>如果只知道前序遍历和后序遍历则无法确定左右子树的长度，从而无法确认二叉树**。</font>

**▧ 树的广度优先遍历**

&emsp;&emsp;广度优先遍历遵循“逐层推进”的规则，通常借助“队列”来实现。广度优先遍历的复杂度分析如下：
&emsp;&emsp; &emsp; ● **时间复杂度为 $O(n)$** ：所有节点被访问一次，使用 $O(n)$ 时间，其中 n 为节点数量。
&emsp;&emsp; &emsp; ● **空间复杂度为 $O(n)$** ：在最差情况下 (满二叉树时) ，队列中最多同时存在 $(n+1)/2$ 个节点，占用 $O(n)$ 空间。
![[../picture/Pasted image 20240831175638.png#pic_center|260]]
```java
public MyLinkedList<T> levelOrder(TreeNode<T> root){  
    MyLinkedList<T> result = new MyLinkedList<>();  
    MyQueue<TreeNode<T>> queue = new MyQueue<>();  
    queue.enqueue(root);  //将根节点入队
    while(!queue.isEmpty()){  
        TreeNode<T> node = queue.dequeue();  //从队中拿出队首元素并读取数据
        result.add(node.val);  
        if(node.left != null){  //先将队首元素对应的左节点入队
            queue.enqueue(node.left);  
        }  
        if(node.right != null){ //再将队首元素对应的左节点入队
            queue.enqueue(node.right);  
        }  
    }  
    return result;  
}
```

**▧ 树的深度优先遍历**

&emsp;&emsp; 深度优先遍历是一种用于遍历或搜索树或图的算法。在深度优先搜索中，我们从一个初始顶点出发，探索尽可能远的顶点，直到没有未访问的相邻顶点为止，然后回溯，继续探索其他分支。这一过程可以用一个栈来辅助实现，每次访问一个新的顶点时，将其压入栈中，当需要回溯时，从栈中弹出顶点。
![[../picture/Pasted image 20240831175839.png#pic_center|450]]
```java
//DFS先序遍历
private void DFSFirstOrderForRecursion(TreeNode<T> root,MyLinkedList<T> result){  
    if(root == null){  
        return;  
    }  
    result.add(root.val);  
    DFSFirstOrderForRecursion(root.left,result);  
    DFSFirstOrderForRecursion(root.right,result);  
}

//DFS中序遍历
private void DFSInOrderForRecursion(TreeNode<T> root,MyLinkedList<T> result){  
    if(root == null){  
        return;  
    }  
    DFSInOrderForRecursion(root.left,result);  
    result.add(root.val);  
    DFSInOrderForRecursion(root.right,result);  
}

//DFS后序遍历
public MyLinkedList<T> DFSLastOrder(TreeNode<T> root,FunctionType type){  
    MyLinkedList<T> result = new MyLinkedList<>();  
    switch (type){  
        case STACK:  
            DFSLastOrderForStack(root,result);  
            break;  
        case RECURSION:  
            DFSLastOrderForRecursion(root,result);  
            break;  
    }  
    return result;  
}
```

###### (2). 二叉查找(搜索)树 - BST
&emsp;&emsp;二叉搜索树 (Binary Sort Tree) 又称二叉排序树、二叉查找树，是一种特殊结构的树。<font color=red>**BST可以用于数据的排序存储，其中序遍历得到的结果是一个有序(升序)的序列**</font>，且<font color=read>**数据查找的时间复杂度与二分查找的时间复杂度相同**</font>。虽然二叉搜索树在数据排序存储方面有很高的效率，但是不同的排序方式会导致二叉搜索树<font color=orange> "**失去平衡**"</font>，退化成只有一个分支的 "链表"。二叉查找树具有以下特点：
&emsp;&emsp; &emsp;  ① 若它的左子树不为空，则左子树的所有节点的值都小于根节点的值，即**【左子树 < 根节点】。**
&emsp;&emsp; &emsp;  ② 若它的右子树不为空，则右子树的所有节点的值都大于根节点的值，即**【右子树 > 根节点】。**
&emsp;&emsp; &emsp;  ③ 它的左右子树也分别为二叉搜索树。需要注意：不能仅凭某个【右节点 > 根节点 > 左节点】来判断是否是二叉搜素树。
&emsp;&emsp; &emsp; ④ 二叉搜索树<font color=read>**只支持增删查，并不支持改**</fonts>，因为随意修改会导致节点可能不满足二叉搜索树的条件。
![[../picture/Pasted image 20240831224349.png#pic_center|220]]

**▧ BST 的数据插入**

&emsp;&emsp; 为了保持二叉搜索树【左子树 < 根节点 < 右子树】的性质，二叉搜索树不允许存在重复节点。因此，若待插入节点在树中已存在，则不执行插入，直接返回。 为了实现插入节点，我们需要借助节点 `pre` 保存上一轮循环的节点。这样在遍历至 `None` 时，可以获取到其父节点，从而完成节点插入操作。BST 的插入操作流程如下：
&emsp;&emsp; &emsp; **👣 Step 1**：查找插入位置：从根节点出发，根据当前节点值和 `num` 的大小关系循环向下搜索，直到越过叶节点 (遍历至 `None`) 时跳出循环。
&emsp;&emsp; &emsp; **👣 Step 2**： 在该位置插入节点，初始化节点 `num` ，将该节点置于 `None` 的位置。
```java
public TreeNode<Integer> insertForBST(TreeNode<Integer> root,Integer value){  
    if(root == null){  
        root = new TreeNode<Integer>(value);  
    }  
    TreeNode<Integer> curNode = root;  
    TreeNode<Integer> preNode = null;  
    // Step 1：查找插入位置，并越过叶节点
    while(curNode != null){  
        if(curNode.val == value){  
            return root;  
        }  
        preNode = curNode;  
        if(curNode.val < value){  
            curNode = curNode.right;  
        }else if(curNode.val > value){  
            curNode = curNode.left;  
        }  
    }  
     // Step 2：在该位置插入节点，初始化节点，将该节点置于 `None` 的位置。
    TreeNode<Integer> newNode = new TreeNode<Integer>(value);  
    if(preNode.val < value){  
        preNode.setRight(newNode);  
    }else if(preNode.val > value){  
        preNode.setLeft(newNode);  
    }  
    return root;  
}
```

**▧ BST 的数据删除**

&emsp;&emsp; BST 的数据删除，需要先在二叉树中查找到目标节点，再将其删除。为了保证二叉搜索树【左子树 < 根节点 < 右子树】的性质，需要根据目标节点的子节点数量，分 0、1 和 2 三种情况，执行对应的删除节点操作。

![[../picture/Pasted image 20240901234811.png#pic_center|700]]

```java
public TreeNode<Integer> deleteForBST(TreeNode<Integer> root,Integer val){  
    if(root == null){  
        return root;  
    }  
    TreeNode<Integer> curNode = root;  
    TreeNode<Integer> preNode = null;  
    //Step 1：查找待删除节点
    while(curNode != null){  
        if(curNode.val == val){  
            break;  
        }  
        preNode = curNode;  
        if(curNode.val > val){  
            curNode = curNode.left;  
        }else{  
            curNode = curNode.right;  
        }  
    }  
    if (curNode == null) {  
        return root;  
    }  
     //Step 2：处理待删除节点的度为0或1
    if(curNode.left == null || curNode.right == null){  
        TreeNode<Integer> child = curNode.left == null ? curNode.right : curNode.left;  
       
        if(curNode != root){  
            if(preNode.left == curNode){  
                preNode.left = child;  
            }else{  
                preNode.right = child;  
            }  
        }else{  
            root = child;  
        }  
    }else{
    //Step 3：处理待删除节点的度为2，查找后继结点 (左节点查询其右子树，右节点查询其左子树)
        TreeNode<Integer> temp = curNode.left;  
        while(temp != null){  
            temp = temp.right;  
        }  
        curNode.val = temp.val;  
        root = deleteForBST(root,temp.val);  
    }  
    return root;  
}
```

###### (3). 平衡二叉树 - AVL
&emsp;&emsp;二叉搜索树(BST)在多次插入和删除操作后，可能退化为链表，在这种情况下，所有操作的时间复杂度将从 O(log⁡n) 退化为 O(n) 。
![[../picture/Pasted image 20241110223222.png#pic_center|480]]
&emsp;&emsp;&emsp; 为了避免出现退化现象，G. M. <font color=red>A</font>delson-<font color=red>V</font>elsky 和 E. M. <font color=red>L</font>andis两人在1962年提出了平衡二叉树 (AVL)。AVL 树在持续添加和删除节点后，确保 AVL 树不会退化，从而使得各种操作的时间复杂度保持在 O(log⁡n) 级别。因此在需要频繁进行增删查改操作的场景中，AVL 树能始终保持高效的数据操作性能。
&emsp;&emsp;&emsp;  AVL 树的特点在于“**旋转**”操作，它能够在不影响二叉树的中序遍历序列的前提下，使失衡节点重新恢复平衡，从而保持查询的时间复杂度维持在 O(log⁡n) 。为了能够判断何时旋转，AVL 树需要计算出<font color=read>**节点的高度，即从该节点到它的最远叶节点的距离 (所经过的“边”的数量)，需要注意的是，叶节点的高度为 0 ，而空节点的高度为 −1**</font>。为了可以判断BST出现的退化现象，引入了<font color=orange>**节点的平衡因子(balance factor) = 节点左子树的高度 - 节点右子树的高度**</font>，同时规定空节点的平衡因子为 0。当树中节点的平衡因子绝对值 > 1 时，该节点称为“**失衡节点**”。根据节点失衡情况的不同，非平衡二叉树主要分为四类：**LL型、RR型、LR型、RL型**。同时针对这四类非平衡二叉树对应四种旋转操作将非平衡二叉树调整为平衡二叉树，四种旋转操作分为：<font color=red>**右旋、左旋、先右旋后左旋、先左旋后右旋**</font>。

**▧ 非平衡二叉树种类**

&emsp;&emsp;● **第一类 - LL型**：根节点的左孩子的左孩子引起的树不平衡。可能是左孩子的左孩子加进来。或者左孩子的左孩子又加了一个孩子进来，导致左子树的高度过高。
![[../picture/Pasted image 20241115233008.png]]

&emsp;&emsp;● **第二类 - RR型**：根节点的右孩子的右孩子引起的树不平衡。可能是右孩子的右孩子加进来；或者右孩子的右孩子又加了一个孩子进来，导致右子树的高度过高。
![[../picture/Pasted image 20241115233024.png]]

&emsp;&emsp;● **第三类 - LR型**：根节点的左孩子的右孩子引起的树不平衡。可能是左孩子的右孩子加进来；或者左孩子的右孩子又加了一个孩子进来，导致左子树的高度过高。
![[../picture/Pasted image 20241116153026.png]]

&emsp;&emsp;● **第四类 - RL型**：根节点的右孩子的左孩子引起的树不平衡。可能是右孩子的左孩子加进来；或者右孩子的左孩子又加了一个孩子进来，导致右子树的高度过高。
![[../picture/Pasted image 20241116154518.png]]

&emsp;&emsp;根据上面的四种非平衡二叉树的分类，我们通过判断失衡节点的平衡因子以及较高一侧子节点的平衡因子的正负号，来确定失衡节点的平衡调整旋转方法。
![[../picture/Pasted image 20241116170825.png#pic_center|480]]

**▧ AVL左旋**

&emsp;&emsp;AVL左旋操作步骤是将失衡节点(T)自己变为右孩子的左孩子，同时原有失衡节点(T)的右孩子的左孩子变为失衡节点(T)的右孩子。
![[../picture/Pasted image 20241116213057.png#pic_center|680]]
```java
/* 左旋操作 node为失衡节点 */
TreeNode leftRotate(TreeNode node) {
    TreeNode child = node.right;       //记录失衡节点的右孩子
    TreeNode grandChild = child.left;  //记录失衡节点右孩子的左孩子
    // 以 child 为原点，将 node 向左旋转
    child.left = node;        //失衡节点自己变为右孩子的左孩子
    node.right = grandChild;  //失衡节点右孩子的左孩子,变为失衡节点的右孩子。
    // 更新节点高度
    updateHeight(node);
    updateHeight(child);
    // 返回旋转后子树的根节点
    return child;
}
```

**▧ AVL右旋**

&emsp;&emsp;AVL右旋操作步骤是将失衡节点(T)自己变为左孩子的右孩子，同时原有失衡节点(T)的左孩子的右孩子变为失衡节点(T)的左孩子。
![[../picture/Pasted image 20241116221251.png#pic_center|680]]
```java
/* 右旋操作 node为失衡节点 */
TreeNode rightRotate(TreeNode node) {
    TreeNode child = node.left;        //记录失衡节点的左孩子
    TreeNode grandChild = child.right; //记录失衡节点左孩子的右孩子
    // 以 child 为原点，将 node 向右旋转
    child.right = node;        //失衡节点自己变为左孩子的右孩子
    node.left = grandChild;    //失衡节点左孩子的右孩子，变为失衡节点的左孩子
    // 更新节点高度
    updateHeight(node);
    updateHeight(child);
    // 返回旋转后子树的根节点
    return child;
}
```

**▧ AVL先左旋后右旋**

![[../picture/Pasted image 20241116223808.png#pic_center|430]]

**▧ AVL先右旋后左旋**
![[../picture/Pasted image 20241117151652.png#pic_center|430]]

```java
/* AVL旋转操作，使该子树重新恢复平衡 */
TreeNode rotate(TreeNode node) {
    int balanceFactor = balanceFactor(node); // 获取节点 node 的平衡因子
    if (balanceFactor > 1) {                 // 左偏树
        if (balanceFactor(node.left) >= 0) {
            return rightRotate(node);           // 右旋
        } else {
            node.left = leftRotate(node.left);  // 先左旋后右旋
            return rightRotate(node);
        }
    }
    if (balanceFactor < -1) {               // 右偏树
        if (balanceFactor(node.right) <= 0) {
            return leftRotate(node);        // 左旋
        } else {
            node.right = rightRotate(node.right); // 先右旋后左旋
            return leftRotate(node);
        }
    }
    // 平衡树，无须旋转，直接返回
    return node;
}
```

#### 1.2.4
---
### 1.3 算法
&emsp;&emsp;算法与数据结构之间的关系是相互依存的，算法需要数据结构来存储和操作数据，而数据结构需要算法来操作和处理数据。在算法问题中，重要的是对问题的理解和思考，从而选取合适的算法。面对一个问题，存在不同的结题思路，如何选取一个合适的算法就需要对各个算法的本质进行深入的了解。
#### 1.3.1 算法复杂度分析
&emsp;&emsp;在算法设计中，在能够解决问题的前提下，算法效率已成为衡量算法优劣的主要评价指标，它包括以下两个维度。
&emsp;&emsp;&emsp;  ①  **时间效率**：算法运行时间的长短。
&emsp;&emsp;&emsp;  ② **空间效率**：算法占用内存空间的大小。

##### 1.时间复杂度 - time complexity
&emsp;&emsp;算法的时间复杂度是一个函数 T(n)，时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**。时间复杂度常用大O符号表示，表示时间复杂度函数 T(n) 的渐近上界 (asymptotic upper bound），**不包括这个函数的低阶项和首项系数**。<font color=red>**程序的运行时间与算法的时间复杂度相关，也和数据规模有关。**</font>一个合适的程序需要根据不同的数据规模选取不同时间复杂度的算法。如果可以在1s内解决问题，那么对应的处理数据的数量级如下所示：
![[../picture/Pasted image 20231125165206.png#pic_center|200]]

**▧ 算法复杂度类型** 
&emsp;&emsp;设输入数据大小为 n ，常见的时间复杂度类型如下：

![[../picture/Pasted image 20240810103345.png#pic_center|440]]
![[../picture/Pasted image 20240810160307.png#pic_center|540]]
- 常数阶 $O(1)$：常数阶的操作数量与输入数据大小 n 无关，即不随着 n 的变化而变化。
- 线性阶 $O(n)$：线性阶的操作数量相对于输入数据大小 n 以线性级别增长。线性阶通常出现在单层循环中：
- 平方阶 $O(n^2)$：平方阶的操作数量相对于输入数据大小 n 以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环的时间复杂度都为 $O(n)$ ，因此总体的时间复杂度为$O(n^2)$。
- 指数阶 $O(2^n)$：指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。
- 对数阶 $O(logn)$：对数阶反映了“每轮缩减到一半”的情况。设输入数据大小为 n ，由于每轮缩减到一半，因此循环次数是 $log_2⁡n$ ，即 2n 的反函数。对数阶常出现于基于分治策略的算法中，体现了“一分为多”和“化繁为简”的算法思想。它增长缓慢，是仅次于常数阶的理想的时间复杂度。
- 线性对数阶 $O(nlogn)$：线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为 $O(log⁡n)$ 和 $O(n)$。主流排序算法的时间复杂度通常为 $O(nlog⁡n)$ ，例如快速排序、归并排序、堆排序等
- 阶乘阶 $O(n!)$：阶乘阶对应数学上的“全排列”问题。给定 n 个互不重复的元素，求其所有可能的排列方案，方案数量为：$n! = n ×(n-1)×(n-2)×...×2×1$
- 
**▧ 常见程序的算法复杂度分析** 
&emsp;&emsp;&emsp;在计算程序性能时，虽然经常化简为最高项 $2N^2+cN ≈ 2N^2$ ，但当常数项很大时，如 $c=10^6$，我们也不能忽略常数项。
![[../picture/Pasted image 20231125165326.png#pic_center|780]]
**▧ 提高程序的性能**  
&emsp;&emsp;&emsp;要提高程序的性能，就是降低或稳定程序的时间复杂度，一般从两个方面进行： 
&emsp;&emsp;&emsp;  ◎ **处理对于输入的依赖**：程序计算的目的就是找到输入集合的性质，因此如果我们能够在集合中找到其性质，就可以使用经典的数学分析来简化程序处理对输入的依赖。     
&emsp;&emsp;&emsp;  ◎ **最坏情况下性能的保证**：保证程序的性能下限。     
&emsp;&emsp;&emsp;  ◎ **随机化算法**：尽快能的保证算法的随机性。如对随机算法的改进。

##### 2.空间复杂度 - space complexity
&emsp;&emsp;空间复杂度用于衡量算法占用内存空间随着数据量变大时的增长趋势。

#### 1.3.2 程序控制结构
&emsp;&emsp; 在算法中，重复执行某个任务是很常见的，它与复杂度分析息息相关。在程序中实现重复执行任务，存在两种基本的程序控制结构：**迭代、递归**。两者的特点如下：

![[../picture/Pasted image 20240810101505.png#pic_center|500]]
##### 1.迭代 iteration
&emsp;&emsp; 迭代是用计算机处理问题的一种基本方法，是一种重复执行某个任务的控制结构。在迭代中，程序会在满足一定的条件下重复执行某段代码，直到这个条件不再满足。它利用计算机运算速度快、适合做重复性操做的特点，让计算机对一组指令(或一定步骤)进行重复执行，在每次执行这组指令(或这些步骤)时，都从变量的原值推出它的一个新值。利用迭代算法处理问题，需要做好以下三个方面：
&emsp;&emsp;&emsp;  ① 确定迭代变量：在能够用迭代算法处理的问题中，至少具有一个间接或间接地不断由旧值递推出新值的变量，这个变量就是迭代变量。
&emsp;&emsp;&emsp;  ② 建立迭代关系式：指如何从变量的前一个值推出其下一个值的公式(或关系)。迭代关系式的建立是处理迭代问题的关键，通常能够使用递推或倒推的方法来完成。
&emsp;&emsp;&emsp;  ③ 对迭代过程进行控制：不能让迭代过程无休止地重复执行下去。迭代过程的控制通常可分为两种情况：一种是所需的迭代次数是个确定的值，能够计算出来;另一种是所需的迭代次数无法确定，需要进一步分析出用来结束迭代过程的条件。

##### 2.递归 recursion
&emsp;&emsp; 在数学与计算机科学中，递归是指在函数的定义中使用函数自身的方法。实际上，递归其包含了两个意思：**递** 和 **归**，这正是递归思想的精华所在。**递归就是有去 ( 递去 ) 有回 ( 归来 )**，其本质是<font color=red>将递归的函数在递去的过程中入栈 (操作系统层面的函数调用栈)，在归来的过程中出栈，并在入栈过程中缓存了当前递归状态的函数中的局部变量的内容</font>。    
&emsp;&emsp;&emsp;  ◎ **"递去"** 是指：递归问题必须可以分解 ( 展开 ) 为若干个规模较小，与原问题形式相同的子问题，这些子问题可以用相同的解题思路来解决。    
&emsp;&emsp;&emsp;  ◎ **“归来”** 是指：递归问题的演化过程是一个从大到小，由近及远的过程，并且会有一个明确的终点 (临界点)，一旦到达了这个临界点，就不用再继续走下去。最后从这个临界点开始，原路返回到原点，原问题解决。
![[../picture/Pasted image 20231125165623.png#pic_center|600]]
&emsp;&emsp;&emsp;递归的基本思想就是**把规模大的问题转化为规模小的相似的子问题来解决**。特别地，在函数实现时，因为解决大问题的方法和解决小问题的方法往往是同一个方法，所以就产生了函数调用它自身的情况，这也正是递归的定义所在。格外需要注意的是，**这个解决问题的函数必须有明确的结束条件，否则就会导致无限递归的情况**。因此递归存在以下**三要素**：   
&emsp;&emsp;&emsp;  ◎ **明确递归终止条件**：程序一旦到达了这个临界点，说明当前问题已经被分解为最小子问题，此时就不用继续往下递去而是开归来。    
&emsp;&emsp;&emsp;  ◎ **给出递归终止时的处理办法**：在递归的临界点，应该给出这个最小子问题的解决方案。一般地，最小子问题的解决方案是直观的、容易的。    
&emsp;&emsp;&emsp;  ◎ **提取重复的逻辑，缩小问题规模**：递归问题必须可以分解为若干个规模较小、与原问题形式相同的子问题。因此需要抽象出一个干净利落的重复的逻辑，以便使用相同的方式解决子问题。

###### (1). 递归算法的编程模型
&emsp;&emsp;在明确递归算法设计三要素后，在编写算法时，通常有两种典型的递归算法设计模型：
```
① 模型一：在递去的过程中解决问题(尾递归)  
function recursion(大规模){  
    if (end_condition){    // 明确的递归终止条件  
        return end;      // 简单情景  
    }     
    // 在将问题转换为子问题的每一步，解决该步中剩余部分的问题           
    solve;             // 递去过程中不断解决问题  
    recursion(缩小规模); // 递到最深处后，不断地归来  
    
}  
② 模型二：在归来的过程中解决问题  
function recursion(大规模){  
    if (end_condition){   // 明确的递归终止条件  
        return end;     // 简单情景  
    }
    // 先将问题全部描述展开，再由尽头“返回”依次解决每步中剩余部分的问题
    recursion(缩小规模);// 递去  
    solve;             // 归来过程中不断解决问题    
}
```

**▧ 递归的具体例子**
- 🌰 **例子1**：二叉树的中序遍历 
```java
private void DFSInOrderForRecursion(TreeNode<T> root,MyLinkedList<T> result){  
    if(root == null){  
        return;  
    }  
    DFSInOrderForRecursion(root.left,result);  
    //在递归的过程中，每次执行 DFSInOrderForRecursion(root.left,result); 操作时相当于将下面两个操作入栈，当触发终止条件root = null时，下面两个操作开始依次出栈调用。
    result.add(root.val);  
    DFSInOrderForRecursion(root.right,result);  
}
```
- 

###### (2). 递归算法的应用场景
&emsp;&emsp;递归算法一般用于解决三类问题：    
&emsp;&emsp;&emsp;  ◎ **问题的定义是按递归定义的 ( 如 Fibonacci 函数，阶乘，… )**   
&emsp;&emsp;&emsp;  ◎ **问题的解法是递归的 ( 有些问题只能使用递归方法来解决，例如，汉诺塔问题，… )**    
&emsp;&emsp;&emsp;  ◎ **数据结构是递归的 ( 如链表、树等的操作，包括树的遍历，树的深度，… )**


#### 1.3.3 算法思想
&emsp;&emsp; 面对一个问题，存在不同的结题思路，因此学习算法就要面对问题取求解。
##### 1. 遍历搜索算法
&emsp;&emsp; 在探索复杂的数据结构和算法问题时，首先想到的便是数据的遍历与查找。遍历是一种基础但却极为关键的概念。遍历是对数据结构中的元素进行访问和检查的过程。常见的遍历算法，包括广度优先遍历、深度优先遍历等。

###### (1). 广度优先遍历 - Breadth-First Search, BFS
&emsp;&emsp;广度优先遍历是一种图和树的遍历策略，它的核心思想是从一个起始节点开始，访问其所有邻近节点，然后再按照相同的方式访问这些邻近节点的邻近节点。在广度优先遍历中，我们通常使用一个队列（Queue）来存储待访问的节点。初始时，将起始节点放入队列。然后，执行以下操作直到队列为空：
&emsp;&emsp;&emsp; **Step 1**：从队列中取出一个节点。
&emsp;&emsp;&emsp; **Step 2**：访问该节点，并将其标记为已访问。
&emsp;&emsp;&emsp; **Step 3**：将该节点的所有未被访问的邻近节点加入队列。


###### (2). 深度优先遍历 - Depth-First Search, DFS
&emsp;&emsp; 深度优先遍历是一种用于遍历或搜索树或图的算法。在深度优先搜索中，我们从一个初始顶点出发，探索尽可能远的顶点，直到没有未访问的相邻顶点为止，然后回溯，继续探索其他分支。这一过程需要用一个栈来辅助实现，每次访问一个新的顶点时，将其压入栈中，当需要回溯时，从栈中弹出顶点。

##### 2. 查找算法


查找是在大量的信息中寻找一个特定的信息元素。在非数值运算问题中，数据存储量一般很大，为了在大量信息中找到某些值，需要用到查找技术，为了提高查找效率，需要对一些数据进行排序。查找和排序的数据处理量占有非常大的比重，故查找和排序的有效性直接影响到算法的性能，因而查找和排序是重要的处理技术。查找两种常见的分类：

##### 2. 排序算法
